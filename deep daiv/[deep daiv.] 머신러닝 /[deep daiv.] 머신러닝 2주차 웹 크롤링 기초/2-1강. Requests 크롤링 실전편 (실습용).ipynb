{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBKIuehH7uDp"
   },
   "source": [
    "# 2-1강. 크롤링 실전편\n",
    "정해진 기간 동안의 뉴스 기사를 크롤링하는 코드를 작성해봅시다.<br>\n",
    "한 단어로 표시되는 뉴스 기사 수는 제한되어 있습니다. 그래서 하루 단위로 필터링하여 놓치는 기사 없이 모두 수집해보려고합니다.<br>\n",
    "조금 더 재미 있는 코드들을 소개해드릴게요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJkWuBiraHok"
   },
   "source": [
    "### 이번주 뉴스 기사 URL 수집\n",
    "본격적으로 URL을 조작하여 지난 한 주 동안의 뉴스 기사를 수집해봅시다.<br>\n",
    "여기서는 날짜 리스트를 만들어야 하는데, 어떻게 만들면 더 쉬운지 알아보고<br>\n",
    "사용자 정의 함수를 구현하여 조금 더 효율적이고 이해 가능한 코드를 구현해봅시다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_Hc6doet83q"
   },
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkEPZ0fz4wmy"
   },
   "outputs": [],
   "source": [
    "# 임시 URL 설정\n",
    "tmp_url = 'https://search.naver.com/search.naver?where=news&sm=tab_pge&query=AI&sort=2&photo=0&field=0&pd=3&ds=2023.02.01&de=2023.02.01&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:from20230201to20230201,a:all&start=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mg4wP-rv5Ew5"
   },
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "from urllib.parse import parse_qs\n",
    "\n",
    "# 위의 복잡한 URL은 사실 요청문으로 이루어져 있습니다. 여기에서 정보를 빠르고 쉽게 추출할 수 있어요!\n",
    "# Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SyTDkOtDAX0H"
   },
   "outputs": [],
   "source": [
    "# 파라미터 변경\n",
    "params['start'] = 1 # 이 값은 저희가 추후에 변경해야 하는 부분이라 리스트 형태에서 정수 형태로 미리 바꾸어두었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XS0TC4eY8XHh"
   },
   "outputs": [],
   "source": [
    "# 날짜 리스트 생성\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "today = # Your Code\n",
    "last_week = # Your Code\n",
    "\n",
    "today = # Your Code\n",
    "last_week = # Your Code\n",
    "\n",
    "import pandas as pd\n",
    "date_list = # Your Code\n",
    "#Pandas에서 날짜 리스트를 쉽게 얻을 수 있습니다. 저희가 알고 있는 문자열이 아니라, 날짜 데이터를 조금 더 유연하게 다룰 수 있는 형식으로 저장됩니다.\n",
    "print(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y9hOybG77Qiy"
   },
   "outputs": [],
   "source": [
    "# 뉴스 URL 수집 | 매일 첫 페이지만\n",
    "url = 'https://search.naver.com/search.naver'\n",
    "\n",
    "news_url_list = []\n",
    "for date in date_list:\n",
    "    #\n",
    "\n",
    "    news_url_list_part = soup.find_all('a', 'info', text = '네이버뉴스')\n",
    "    print(date_string, len(news_url_list_part), '개')\n",
    "    news_url_list.extend(news_url_list_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KkcWHsrWl7vE"
   },
   "outputs": [],
   "source": [
    "def get_soup(url, params):\n",
    "    #\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oIhp_540l7oG"
   },
   "outputs": [],
   "source": [
    "def get_news_url_list(soup):\n",
    "    #\n",
    "    return news_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o6l4bmNOlsMl"
   },
   "outputs": [],
   "source": [
    "def get_page_list(soup):\n",
    "    #\n",
    "    return page_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hu1O0hJ6LVIX"
   },
   "outputs": [],
   "source": [
    "def get_daily_news(url, params):\n",
    "    #\n",
    "    print(len(news_url_list), '개,', n-1, '페이지')\n",
    "    return news_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zpyrtG30FKRM"
   },
   "outputs": [],
   "source": [
    "# 뉴스 URL 수집 | 하루\n",
    "date = date_list[0]\n",
    "params['start'] = 1\n",
    "\n",
    "date_string = date.strftime('%Y.%m.%d')\n",
    "params['ds'] = date_string\n",
    "params['de'] = date_string\n",
    "params['nso'] = 'so:r,p:from{fr}to{to}'.format(fr = date.strftime('%Y%m%d'), to = date.strftime('%Y%m%d'))\n",
    "time.sleep(1)\n",
    "\n",
    "print(date_string)\n",
    "daily_news_list = get_daily_news(url, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "us1AAcfjP6Yc"
   },
   "outputs": [],
   "source": [
    "# (참고) 뉴스 URL 수집 | 모든 페이지\n",
    "url = 'https://search.naver.com/search.naver'\n",
    "params = parse_qs(urlparse(tmp_url).query)\n",
    "\n",
    "news_url_list = []\n",
    "for date in date_list:\n",
    "    params['start'] = 1\n",
    "\n",
    "    date_string = date.strftime('%Y.%m.%d')\n",
    "    params['ds'] = date_string\n",
    "    params['de'] = date_string\n",
    "    params['nso'] = 'so:r,p:from{fr}to{to}'.format(fr = date.strftime('%Y%m%d'), to = date.strftime('%Y%m%d'))\n",
    "    time.sleep(1)\n",
    "    \n",
    "    print(date_string)\n",
    "    daily_news_list = get_daily_news(url, params)\n",
    "    news_url_list.extend(daily_news_list)\n",
    "\n",
    "# 1주일 분량에 46분 30초 소요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x749z0f8qurk"
   },
   "outputs": [],
   "source": [
    "# 수집된 URL 개수 확인\n",
    "len(daily_news_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gm7EeD-UZcuJ"
   },
   "outputs": [],
   "source": [
    "# 뉴스 URL 추출\n",
    "news_url_list = list(map(lambda x : x.get('href'), daily_news_list))\n",
    "\n",
    "# for문을 이용하지 않고 뉴스 맵 함수를 이용하여 빠르게 URL을 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18hCf-qHZW0Y"
   },
   "outputs": [],
   "source": [
    "# URL 데이터 프레임으로 변환\n",
    "df = pd.DataFrame(news_url_list, columns = ['URL']); df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8LL4uWoLJoKT"
   },
   "outputs": [],
   "source": [
    "# URL 데이터 프레임 저장\n",
    "\n",
    "file_name = '네이버 뉴스_AI_{}.csv'.format(date_string)\n",
    "df.to_csv(path + file_name, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQD5gN7Ua8j5"
   },
   "source": [
    "## 뉴스 기사 본문 수집 복습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXu0bxIZaApg"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wa3DwVAvbKu6"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path + '네이버 뉴스_AI_{}.csv'.format(date_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9qJEpTlbecj"
   },
   "outputs": [],
   "source": [
    "test_url = df['URL'][1]\n",
    "\n",
    "res = urlopen(test_url)\n",
    "html = res.read().decode('utf-8')\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aw9wnAAmbj_4"
   },
   "outputs": [],
   "source": [
    "# 뉴스 기사 제목 수집\n",
    "title = # Your Code\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sf9IITJKcS07"
   },
   "outputs": [],
   "source": [
    "# 뉴스 기사 본문 수집\n",
    "content = # Your Code\n",
    "\n",
    "content = # Your Code\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sWOqnmfVc4Ao"
   },
   "outputs": [],
   "source": [
    "# 언론사 수집\n",
    "press = # Your Code\n",
    "print(press)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79skuIzDdxJr"
   },
   "outputs": [],
   "source": [
    "# 날짜 데이터 변환\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "date = # Your Code\n",
    "date = # Your Code\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ac1nmBvKpZTm"
   },
   "outputs": [],
   "source": [
    "# 반복문의 진행 상황을 알려주는 패키지: tqdm\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HCrVO0M4hJ9O"
   },
   "outputs": [],
   "source": [
    "data_list = []\n",
    "error_list = []\n",
    "\n",
    "for url in tqdm(df['URL']):\n",
    "    try:\n",
    "        res = urlopen(url)\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        error_list.append(url)\n",
    "        print(url)\n",
    "        time.sleep(1)\n",
    "        continue\n",
    "\n",
    "    if 'entertain.naver.com' in res.url or 'sports.news.naver.com' in res.url:\n",
    "        error_list.append(url)\n",
    "        print(url)\n",
    "        continue\n",
    "\n",
    "    html = res.read().decode('utf-8')\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    # 타이틀\n",
    "    title = soup.find('h2').text.strip()\n",
    "\n",
    "    # 본문 내용\n",
    "    content = soup.find('div', {'id' : 'dic_area'}).text.strip()\n",
    "    content = re.sub('\\n+', '\\n', content)\n",
    "\n",
    "    # 언론사\n",
    "    press = soup.find('img', 'media_end_head_top_logo_img light_type').get('title')\n",
    "\n",
    "    # 날짜\n",
    "    date = soup.find('span','media_end_head_info_datestamp_time _ARTICLE_DATE_TIME').get('data-date-time')\n",
    "    date = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    data = title, content, press, date\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mj_LuuvPrmyM"
   },
   "outputs": [],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dr0Rg96buvnm"
   },
   "outputs": [],
   "source": [
    "data_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W790DEpSNFDW"
   },
   "outputs": [],
   "source": [
    "news = pd.DataFrame(data_list, columns = ['Title', 'Content', 'Press', 'Date'])\n",
    "news.to_csv(path + '네이버 뉴스 본문_AI.csv', index = False)\n",
    "\n",
    "import pickle\n",
    "with open(path + 'news_list_{}.p'.format(date_string), 'wb') as f:\n",
    "    pickle.dump(data_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h27sGVKnt8L2"
   },
   "outputs": [],
   "source": [
    "with open(path+'news_list_{}.p'.format(date_string), 'rb') as f:\n",
    "    data_list = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM2B9c9qmokncFHIFWTuycy",
   "mount_file_id": "13CG8-QjZmgYGnlYyMsnvCMaHwS8FfKM9",
   "provenance": [
    {
     "file_id": "13CG8-QjZmgYGnlYyMsnvCMaHwS8FfKM9",
     "timestamp": 1675409224868
    }
   ]
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3 (main, Apr 19 2023, 18:49:55) [Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "1da8bb1e470ff509bdae4e915df9bfc787d66424978116436e3017457e3e36c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
